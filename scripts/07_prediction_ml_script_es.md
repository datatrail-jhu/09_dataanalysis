En la última lección, discutimos que el análisis de datos inferenciales busca aprender algo sobre una población haciendo inferencias a partir de una muestra representativa.

Si bien el objetivo de la inferencia es aprender algo sobre la población, cuando hablamos de predicción, el enfoque está en el individuo. El objetivo del análisis predictivo y los enfoques de aprendizaje automático es entrenar un modelo utilizando datos para hacer predicciones sobre un individuo.

En otras palabras, el objetivo del análisis predictivo es utilizar los datos que tiene ahora para hacer predicciones sobre los datos futuros.

Pasamos mucho tiempo tratando de predecir cosas en la vida diaria: el clima que se avecina, los resultados de los eventos deportivos y los resultados de las elecciones. Anteriormente mencionamos a Nate Silver en Five Thirty Eight, donde intentan predecir los resultados de las elecciones en los EE. UU. (¡Y los eventos deportivos también!). Al utilizar los datos y tendencias de las encuestas históricas y las encuestas actuales, Five Thirty Eight construye modelos para predecir los resultados y la próxima votación presidencial de los Estados Unidos, ¡y ha sido bastante acertado al hacerlo! Los modelos de Five Thirty Eight predijeron con precisión las elecciones de 2008 y 2012 y fueron considerados como un valor atípico en las elecciones de 2016 en los Estados Unidos, ya que fue uno de los pocos modelos que sugirió que Donald Trump tenía posibilidades de ganar.

Predecir el resultado de las elecciones es un ejemplo clave de análisis predictivo, donde los datos históricos (datos que tienen ahora) se usan para predecir algo sobre el futuro. En esta lección, repasaremos las piezas importantes para llevar a cabo un análisis predictivo, qué consideraciones se deben hacer al hacer predicciones, analizaremos qué es el aprendizaje automático y hablaremos sobre cómo evaluar la precisión dentro de un análisis predictivo.

Hasta ahora hemos estado discutiendo el análisis predictivo. Sin embargo, es posible que haya escuchado a personas en las noticias o en la vida cotidiana hablar sobre el "aprendizaje automático". 394100 El objetivo del aprendizaje automático es construir modelos (a menudo denominados algoritmos) a partir de los patrones en datos que se pueden usar para predicciones en el futuro. Para nuestros propósitos, es seguro argumentar que al hacer un análisis predictivo, en realidad estamos haciendo un aprendizaje automático. Como tal, usaremos el aprendizaje automático durante el resto de esta lección. Aquí, el aprendizaje automático se refiere al uso de las relaciones dentro de un conjunto de datos para construir un modelo que se puede usar para la predicción. Dicho esto, hay sin duda un campo completo de individuos dedicados al aprendizaje automático. Esta lección solo tocará los conceptos básicos dentro del campo.

Para hacer predicciones para el futuro utilizando los datos que tiene ahora, hay cuatro pasos generales. Primero, hay una división de datos que determina qué datos va a utilizar para entrenar su modelo, para ejecutar su modelo y para probar su modelo. Segundo, hay una Selección de Variable que determina qué variable o variables de los datos que tiene ahora que usará para predecir resultados futuros. En tercer lugar, hay una selección de modelo que determina cómo se van a modelar los datos. Finalmente, hay una evaluación de precisión que determina cómo se evaluará la precisión de sus predicciones.

Para el análisis predictivo (o aprendizaje automático), necesita datos sobre los cuales capacitar a su modelo. Estos son el conjunto de observaciones y las variables correspondientes que usará para construir su modelo predictivo. Sin embargo, un modelo predictivo solo vale algo si se puede predecir con precisión en un conjunto de datos futuro. Por lo tanto, a menudo, en el aprendizaje automático hay tres conjuntos de datos utilizados para construir un modelo predictivo: entrenar, sintonizar y probar.

Está bien, hay que admitir que estas no son las palabras más comunes para usar en este proceso. Muchas personas usan el tren, validan y prueban. Sin embargo, casi la mayoría de la gente usa el tren, prueba y valida, como lo demuestra esta encuesta de Twitter.

Como tal, mencionamos esos términos para que los conozca, pero como las personas de aprendizaje automático no pueden ponerse de acuerdo sobre el orden de las palabras, en esta lección, hemos decidido utilizar una terminología más útil, como sugerido por Carl de Boer: entrenar, sintonizar y probar.

Los datos de entrenamiento son los datos que describimos anteriormente. Los datos utilizados para construir su modelo predictivo. Estos datos se conocen como su conjunto de entrenamiento.

Antes de comenzar, su conjunto de datos original a menudo se divide. Algunas de las observaciones (a menudo el 70%) de su conjunto de datos se utilizan para entrenar el modelo, mientras que el 30% se mantiene. Este conjunto retenido de observaciones de su conjunto de datos original se usa para mejorar (afinar) la precisión del modelo. Estas muestras de espera se utilizan para ver si su modelo predictivo realiza o no predicciones con precisión en el conjunto de muestras que no se utilizan para entrenar el modelo.

Finalmente, se usa un conjunto de datos independiente, uno que no es del mismo experimento o fuente que los datos utilizados para entrenar y sintonizar su modelo, para ver si su modelo predictivo realiza predicciones precisas en un conjunto de datos completamente nuevo. Los modelos predictivos que pueden generalizarse y hacer predicciones precisas en nuevos conjuntos de datos son los mejores modelos predictivos.

Para que el análisis predictivo valga la pena, debe poder predecir un resultado con precisión con los datos que tiene a mano.

Si todos los datos que tiene a la mano son las alturas de los elefantes en Asia, es probable que no pueda predecir el resultado de la próxima elección en los EE. UU. Por lo tanto, las variables en los datos que tiene a la mano tienen que estar relacionadas con el resultado que le interesa predecir de alguna manera (lo que no es el caso de las alturas de los elefantes y las elecciones de los EE. UU.).

En cambio, para predecir las elecciones en los EE. UU., Es probable que desee algunos datos sobre los resultados de elecciones anteriores, tal vez información demográfica sobre los distritos electorales y tal vez alguna información sobre las edades o profesiones de las personas que votan. Es probable que todas estas variables sean útiles para predecir el resultado en una elección futura, pero ¿cuáles son realmente predictivas? ¿Todos ellos? ¿Algunos? El proceso de decidir qué variables usar para la predicción se llama selección de variables.

Lo ideal es que incluyas la menor cantidad posible de variables en tu modelo. Solo tener algunas variables en su modelo evita tener que recopilar una tonelada de datos o construir un modelo realmente complicado. Sin embargo, desea que el modelo sea lo más preciso posible al hacer predicciones. Por lo tanto, siempre hay un equilibrio entre minimizar las variables incluidas (¡para incluir solo las variables más predictivas!) Y maximizar la precisión predictiva de su modelo. En otras palabras, al igual que en el análisis inferencial, su capacidad para hacer predicciones precisas depende de si tiene o no mediciones sobre las variables correctas. Si no está midiendo las variables correctas para predecir un resultado, sus predicciones no serán precisas. Por lo tanto, la selección de variables, es increíblemente importante. Dicho todo esto, existen enfoques de aprendizaje automático que llevan a cabo la selección de variables, y se utilizan todos los datos para determinar qué variables del conjunto de datos son más útiles para la predicción. Sin embargo, ya sea que decida qué variables incluir o si la computadora decide por usted, la selección de variables es importante para una predicción precisa.

Como recordatorio, como se discutió en el análisis inferencial, solo porque una variable pueda predecir otra, no significa que una cause la otra. En el análisis predictivo, está aprovechando la relación entre dos variables, utilizando una variable (o un conjunto de variables) para predecir una segunda variable. Solo porque una variable predice con precisión otra variable no significa que estén relacionadas causalmente.

Además, hay muchas formas de generar modelos de predicción. Cada modelo fue desarrollado para un propósito diferente y específico. Discutiremos algunos tipos de modelos predictivos aquí, con un enfoque en el uso de regresión lineal. Sin embargo, independientemente del modelo que elija utilizar para la predicción, es mejor tener en cuenta que, en general, cuanta más información tenga y cuanto más simple sea su modelo, más posibilidades tendrá de predecir con precisión los resultados futuros:

Cuantas más observaciones tenga y más variables tenga que elegir para incluir en su modelo, más probabilidades tendrá de generar un modelo predictivo preciso. Sin embargo, tenga en cuenta que los conjuntos de datos grandes con muchos datos faltantes o que se ingresaron incorrectamente no son mejores que los conjuntos de datos pequeños, completos y precisos. Tener un conjunto de datos confiable para construir su modelo es fundamental. Además, si puede predecir con precisión la altura de un individuo considerando solo la altura de los padres de esa persona, entonces hágalo. No es necesario incluir otras variables si una sola variable genera predicciones precisas. Un modelo simple que predice con precisión (independientemente del conjunto de datos en el que predice) es mejor que un modelo complicado.

Antes de pasar a discutir los diversos modelos que puede usar para el análisis predictivo, es importante tener en cuenta la diferencia entre regresión y clasificación. La regresión se usa cuando estás tratando de predecir una variable continua. Por ejemplo, si está tratando de predecir la edad de un individuo, usaría la regresión. Por otro lado, la clasificación se utiliza para las variables categóricas, ya que predice a qué grupo pertenece un individuo. Un ejemplo de una clasificación sería predecir el nivel de educación de alguien, ya que solo hay un número limitado de grupos en los que uno podría estar. Con respecto al aprendizaje automático, ciertos métodos pueden usarse tanto para la regresión como para la clasificación, mientras que otros están diseñados exclusivamente para uno u otro. En esta lección discutiremos un modelo de regresión y un modelo de clasificación. Sin embargo, hay literalmente cientos de modelos disponibles para el modelado predictivo. Por lo tanto, es importante tener en cuenta que en realidad solo estamos rascando la superficie aquí.

¡Al igual que en la lección anterior sobre análisis inferencial, la regresión lineal es un método increíblemente poderoso en el aprendizaje automático! El concepto aquí es el mismo que en la última lección: vamos a capitalizar la relación lineal entre las variables. Sin embargo, en lugar de utilizar la regresión lineal para estimar algo sobre una población más grande, vamos a utilizar la regresión lineal para la predicción de una variable continua.

Para entender mejor esto, usemos un ejemplo conceptual. Considere tratar de predecir la edad de un niño a partir de su altura. Probablemente esperaría que un niño más alto fuera mayor. Entonces, imaginemos que estamos viendo aquí los datos de entrenamiento. Vemos la relación esperada entre la altura y la edad en este diagrama de dispersión.

Utilizando los datos de entrenamiento, se realiza una regresión lineal para modelar la relación.

Ahora que tenemos nuestro modelo, ya no nos preocupamos por los puntos de datos individuales en los datos de entrenamiento. Simplemente usaremos el modelo de regresión lineal para hacer nuestras predicciones.

Luego, en el futuro, cuando conozcamos la altura de un niño, podemos regresar a nuestra regresión lineal, proporcionarle la altura del nuevo niño y devolverá la edad del niño utilizando el modelo que hemos construido. Conceptualmente, esto es lo que sucederá cuando usemos la regresión lineal para el aprendizaje automático. Sin embargo, se llevará a cabo matemáticamente, en lugar de gráficamente. Esto significa que no tendrá que mirar el gráfico para ver sus predicciones. Solo tendrá que ejecutar algunas líneas de código que llevarán a cabo los cálculos necesarios para generar predicciones.

Además, aquí estamos usando una sola variable (altura) para modelar la edad. Claramente, hay otras variables (como el sexo de un niño) que podrían afectar esta predicción. A menudo, los modelos de regresión incluirán múltiples variables predictoras que mejorarán la precisión de la predicción de la variable de resultado.

Alternativamente, cuando intente predecir una variable categórica, querrá ver los métodos de clasificación, como usar un CARRITO para la predicción. Si bien no es el único método de clasificación para el aprendizaje automático, las CART se usan comúnmente para la predicción de variables categóricas. Conceptualmente, cuando se usa un CART para predicción, se genera un árbol de decisión a partir de los datos de entrenamiento. Un árbol de decisión ramifica los datos en función de las variables dentro de los datos. Por ejemplo, si estuviéramos tratando de predecir el nivel de educación de un individuo, probablemente usaríamos un conjunto de datos con información sobre el nivel de ingreso de muchas personas, el título del trabajo y la cantidad de hijos que tienen. Estas variables se utilizarían para generar el árbol. Por ejemplo, tal vez la primera sucursal separaría a las personas que ganan menos de 40,000 dólares al año. Todos aquellos en los datos de entrenamiento que ganaron menos de 40K bajarían por la rama izquierda, mientras que todos los demás bajarían por la rama derecha.

En cada nivel, los datos se seguirán dividiendo, utilizando la información en los datos de capacitación.

Finalmente, se construirá un árbol de decisión completo, de manera que habrá una etiqueta para la variable que estamos tratando de predecir al final de cada rama.

Este CART se utilizará para la predicción en muestras futuras. Por lo tanto, si sigue el camino a lo largo del árbol de decisiones, para este ejemplo CART, un individuo que ganó más de $ 40,000 al año, estaba en una profesión de trabajo manual y tenía hijos, este CART predeciría que el nivel de educación de ese individuo era "Alto Colegio."

De nuevo, esto es conceptual y gráficamente cómo funciona un CARRITO; sin embargo, al generar un CART, usted solo toma de nuevo unas pocas líneas de código para generar el modelo y llevar a cabo los cálculos necesarios.

Un dicho común es que la predicción es difícil, especialmente sobre el futuro. Esto es cierto en el análisis predictivo. Por lo tanto, es importante siempre evaluar cuidadosamente la precisión de su modelo y nunca exagerar qué tan bien puede hacer predicciones. En general, si tus predicciones son correctas, ¡lo estás haciendo bien! Si tus predicciones son erróneas, no lo estás haciendo bien. Pero, ¿cómo definimos "bien"? Para evaluar si nuestros modelos predictivos funcionan bien o no, calculamos las tasas de error. Las dos formas más comunes de evaluar el desempeño de nuestros modelos predictivos son el error y la precisión de la media cuadrática. Notaremos aquí que para evaluar el error, debe conocer la verdad (el valor real) además del valor predicho. Por lo tanto, R M S E y Accuracy se evalúan en los datos de entrenamiento y ajuste, donde se conoce el valor real y el valor predicho.

El error cuadrático medio, o R M S E, es una medida utilizada para evaluar el error de predicción para las variables continuas. En general, queremos minimizar el error en la predicción. Por lo tanto, una pequeña R M S E es mejor que una gran R M S E. Matemáticamente hablando, la R M S E es la raíz cuadrada de la varianza. De lecciones anteriores, sabemos que la variación tiene algo que ver con la confianza que tenemos en nuestra estimación. Ya que estamos tratando de determinar qué tan cerca están nuestras predicciones del valor real, este parece ser un buen lugar para comenzar. Cuando observamos la ecuación, podemos ver que la diferencia entre los valores predichos y los reales se calcula y que este valor se ajusta al cuadrado. Estas diferencias al cuadrado se agregan para cada individuo en su conjunto de datos (eso es lo que dice el sigma, o gran E). Este valor (la suma de todos los errores al cuadrado) se divide por el número de individuos en su conjunto de datos, N. Luego se toma esta raíz cuadrada de este valor. Así es como se calcula R M S E.

Examinamos esa descripción porque queremos señalar que cuando las diferencias son cuadradas, los valores atípicos o las muestras cuya predicción estaba muy alejada de su valor real aumentarán mucho la R M S E. Por lo tanto, algunos valores atípicos pueden llevar a valores R M S E realmente altos, incluso si todas las otras predicciones fueron bastante buenas. Esto significa que es importante verificar si algunos valores atípicos (es decir, algunas predicciones erróneas) están llevando a un alto valor R M S E.

Alternativamente, para evaluar el error en la predicción de variables categóricas, la precisión se utiliza con frecuencia. La precisión busca determinar el número de predicciones que coinciden con sus valores reales. Cuanto más cerca esté este valor al 100%, mejor será su modelo predictivo. Cuanto más cercano al 0%, peores son las predicciones de tu modelo. La precisión es una forma útil de evaluar el error en las variables categóricas, pero también se puede utilizar para valores numéricos. Sin embargo, solo tendrá en cuenta una predicción "correcta"  si coincide exactamente. En el caso de la edad, si la edad de una muestra es 10 y el modelo predice que es 10, el modelo dirá que se ha predicho correctamente. Sin embargo, si la edad de una muestra es 10 y se pronostica que es 9, se contará como incorrecta, aunque sea cercana. Una predicción de apagado por un año se marcará como incorrecta como una muestra predicha fuera de 50 años. Debido a esto, R M S E se opta a menudo en lugar de la precisión para las variables continuas.

Para comprender mejor todos los conceptos que acabamos de analizar, veremos dos ejemplos, uno para la predicción de una variable continua mediante regresión lineal y el segundo para la predicción de un valor categórico mediante un CART. Hay un paquete increíblemente útil disponible en R gracias al trabajo de Max Kuhn. Como se mencionó anteriormente, hay cientos de algoritmos de aprendizaje automático diferentes. El paquete de R de Max ha compilado todos ellos en un solo marco, lo que le permite utilizar muchos modelos diferentes de aprendizaje automático a través de un solo paquete. Además, ha escrito un libro muy útil para acompañar el paquete, cuyo enlace se encuentra en el video. Usaremos este paquete en los siguientes ejemplos.

Para este ejemplo, lo mantendremos simple y usaremos un conjunto de datos que haya visto antes: el conjunto de datos de iris. De esta manera, puede centrarse en la sintaxis utilizada en el paquete caret y en los pasos del análisis predictivo. En este ejemplo, intentaremos usar los datos en el conjunto de datos del iris para predecir la longitud del sépalo

Como se mencionó anteriormente, uno de los primeros pasos a menudo es tomar su conjunto de datos y dividirlo en un conjunto de entrenamiento y un conjunto de ajuste. Para hacer esto, cargaremos el paquete caret y usaremos la función crear partición de datos para dividir el conjunto de datos.

Después de esto, si echamos un vistazo a los conjuntos de datos de entrenamiento y ajuste, podemos ver que el 70 por ciento de nuestras observaciones se encuentran en el conjunto de datos de entrenamiento y el otro 30 por ciento está en el conjunto de datos de ajuste, como especificamos.

¿Qué pasa si primero intentamos predecir la longitud del sépalo en nuestros datos de entrenamiento de Sepal Width? Para hacer eso, proporcionamos la función de tren con el modelo y especificamos que el conjunto de datos que usaremos es el conjunto de datos de iris. Además, le informamos a la función del tren que queremos ejecutar una regresión lineal (lm) y que queremos evaluar la precisión de nuestro modelo utilizando la métrica R M S E.

Después de entrenar el modelo, echamos un vistazo a nuestro R M S E y vemos que es 0.82 para este conjunto de datos.

Usando este modelo, generaríamos predicciones de la longitud del sépalo en el conjunto de datos de ajuste utilizando la función de predicción.

Como conocemos la longitud real del sépalo en el conjunto de afinación, estas predicciones se pueden visualizar utilizando un diagrama de dispersión en el que vemos que las predicciones no son muy buenas dada la falta de corrección entre la longitud real del sépalo y las predicciones.

En este primer intento, especificamos qué variable usar para la predicción; sin embargo, qué sucede si proporcionamos a nuestro modelo de regresión todas las variables en el conjunto de datos (especificado por el punto en el código de la fórmula aquí. De nuevo generaremos predicciones y trazaremos los resultados utilizando un diagrama de dispersión).

Ahora, cuando observamos los resultados, observamos una mejora visual en las predicciones de la longitud del sépalo dentro del conjunto de datos de ajuste, que también se refleja en la disminución de RMS E. Aquí, al incluir variables adicionales (a menudo denominadas características en el aprendizaje automático), ver mejor precisión de predicción. Hay formas más sólidas que probar diferentes variables en su modelo para seleccionar cuáles deben incluirse en su modelo predictivo. Estos serán cubiertos en las lecciones en la pista avanzada de este conjunto de cursos.

En este ejemplo (y el ejemplo que viene), hemos especificado previamente qué modelo íbamos a usar para el ejemplo antes de tiempo. Sin embargo, hay muchos modelos de regresión diferentes entre los que podríamos haber elegido y una serie de parámetros en cada uno que pueden ajustarse, cada uno de los cuales puede mejorar la precisión predictiva de su modelo. Aprender cómo elegir y afinar el mejor modelo se tratará en las lecciones en la pista avanzada de este Conjunto de cursos; sin embargo, por ahora notaremos que, como se especifica en el libro de caret, la función de tren tiene varias capacidades. Puede evaluar cómo los diferentes parámetros de ajuste en el modelo afectan el rendimiento, elegir el modelo 394100 "óptimo", dados estos parámetros, y estimar el rendimiento del modelo (dado un conjunto de entrenamiento). Aquí, no hemos jugado mucho con los parámetros de ajuste; Sin embargo, consultar la documentación sobre cómo hacer esto mediante el enlace del video puede mejorar la predicción a medida que genera modelos predictivos por su cuenta.

Un modelo de predicción más natural dado este conjunto de datos puede ser predecir qué especie es una flor, dadas sus medidas. Usaremos el conjunto de datos del iris para llevar a cabo esta predicción de clasificación aquí, utilizando un CARRITO. La división de datos desde arriba se utilizará aquí. Por lo tanto, nuestro conjunto de entrenamiento seguirá siendo iris_train y nuestro ajuste tuning iris_tune. Dada la naturaleza relativamente pequeña de este conjunto de datos, construiremos el CART utilizando todos los datos; sin embargo, es posible una optimización más robusta de las variables que se incluyen en el modelo dentro del paquete caret. Aquí especificamos que queremos predecir Especies, que queremos usar un CARRITO para hacerlo configurando el método en rf, y que, como es una variable categórica, usaremos Precisión como nuestra métrica de evaluación.

Aquí, vemos que en los datos de ajuste, el CART predijo con precisión las especies de la mayoría de las flores utilizando el modelo generado a partir de los datos de entrenamiento; Sin embargo, hizo dos predicciones incorrectas.

En esta lección hemos cubierto los conceptos básicos de qué es el análisis predictivo, qué tipos de predicción se realizan comúnmente y cómo realizar un análisis predictivo utilizando el paquete caret. Seguramente, esta lección solo ha introducido los conceptos básicos del aprendizaje automático, ¡y todavía hay mucho por aprender para aprender más allá de lo que hay en esta lección!
