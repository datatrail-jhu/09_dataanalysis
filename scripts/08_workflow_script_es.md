En lecciones anteriores, repasamos los conceptos básicos del análisis de datos. Pasamos de cómo hacer preguntas de ciencia de datos y encontrar datos a análisis de datos inferenciales y predictivos. Como científico de datos, puedes terminar trabajando en diferentes proyectos al mismo tiempo. Para evitar que se olviden los pasos importantes que aprendió en este curso, es crucial que siga todos los pasos. En esta lección, vamos a hablar sobre un flujo de trabajo para sus proyectos de análisis de datos.

Para comenzar, estos son los pasos principales que debe seguir en su pregunta de análisis de datos, Definir la pregunta, Definir el conjunto de datos ideal, Determinar a qué datos puede acceder y obtener los datos, Limpiar los datos, Análisis de datos exploratorios, Análisis estadístico, Interpretar resultados, Desafiar resultados, Sintetizar / escribir resultados, Crear código reproducible.

Comencemos con un ejemplo hipotético y repasemos cada paso de nuestro ejemplo. Imagina que estamos interesados ​​en detectar automáticamente los correos electrónicos que son SPAM de los que no lo son. Entonces, nuestra pregunta general es "¿puedo detectar automáticamente los correos electrónicos que son SPAM de los que no lo son?"

Sin embargo, esta pregunta no está escrita completamente en términos de ciencia de datos. Tenemos que asegurarnos de que nuestra pregunta se pueda medir y cuantificar con datos. Tenemos que hacer nuestra pregunta más concreta. Entonces, una mejor manera de hacer la pregunta es esta: "¿Puedo usar características cuantitativas de los correos electrónicos para clasificarlos como SPAM?" 

El segundo paso en el análisis de datos es imaginar un conjunto de datos ideal para nuestro análisis. No tienes que ser práctico en tu pensamiento. Solo imagine qué tipo de datos sería mejor para su análisis. En un mundo ideal, desearía un conjunto de datos de todos los correos electrónicos recibidos a través de los principales proveedores de correo electrónico, como Gmail o Yahoo, y si el correo electrónico fue marcado como SPAM o no.

Puede que tenga suerte de tener tal conjunto de datos de alguna manera. Sin embargo, es poco probable que, por razones de privacidad, pueda acceder a los correos electrónicos de otras personas. Incluso si puede, los datos serán millones de bytes y no será práctico analizar un conjunto de datos tan grande. Así que nuestra mejor apuesta es ver si hay algún conjunto de datos en línea. Uno de los mejores conjuntos de datos para analizar datos de SPAM son los datos de spam en el paquete de kern lab en R. El conjunto de datos de spam se recopila en Hewlett-Packard Labs y clasifica 4601 correos electrónicos como spam o no spam. Además, hay 57 variables que indican la frecuencia de ciertas palabras y caracteres en el correo electrónico. Instalemos el paquete primero.

En la mayoría de los casos, sus datos no son limpios. De hecho, puede provenir de diferentes fuentes con diferentes estándares. Por lo tanto, primero debe ordenar los datos. Por suerte para nosotros, el conjunto de datos de spam en el paquete kern lab ya está ordenado, por lo que podemos omitir este paso. Sin embargo, si estamos haciendo un análisis predictivo, es mejor tener un entrenamiento y un conjunto de pruebas. El siguiente código crea los conjuntos de trenes y pruebas.

Aprendimos sobre los siguientes pasos para realizar análisis de datos exploratorios: mirar resúmenes de los datos, verificar datos faltantes, crear gráficos exploratorios, realizar análisis exploratorios.

Primero, miramos los nombres de las columnas.

Y las primeras filas de nuestros datos de entrenamiento.

Veamos cuántos de los correos electrónicos están marcados como SPAM y cuántos no.

También podemos trazar la longitud promedio de las letras mayúsculas en el texto del correo electrónico para correos electrónicos SPAM y no SPAM. La variable en los datos que mide la longitud promedio de las letras mayúsculas en el texto se llama mayúscula A V E.

Para distinguir mejor la diferencia en el capital A V E para correos electrónicos SPAM y no SPAM, podemos usar la escala de registro. Podemos convertir la variable a log. Tenga cuidado de que si tiene ceros en sus datos (que puede tener), al transformar la variable en un registro, se encontrará con problemas (el registro de cero es infinito). Para evitar esto, podemos agregar 1 a la variable.

Podemos ver si existe alguna relación entre algunos de los predictores, como el libre, el original y el recibir.

El tipo de análisis que necesitamos es análisis predictivo ya que, al final del día, nuestro algoritmo debe predecir si un correo electrónico es SPAM o no. Tenga en cuenta que los métodos exactos dependen de la pregunta de interés. Las transformaciones / el procesamiento deben contabilizarse cuando sea necesario. Las medidas de incertidumbre deben informarse.

Podemos usar el siguiente código para realizar nuestro análisis de predicción utilizando el conjunto de entrenamiento. Tenga en cuenta que la función cv g l m calcula el error estimado de predicción de validación cruzada de K para modelos lineales generalizados. El siguiente fragmento de código encuentra la variable (entre todas nuestras variables) que tiene el error de predicción más bajo para encontrar la probabilidad de ser SPAM.

Luego podemos usar el conjunto de pruebas para obtener una medida de incertidumbre (o precisión) del modelo. Para cada observación en el conjunto de pruebas, predecimos si la observación es un SPAM o no. Tenga en cuenta que ya sabemos si la observación es un SPAM o no, pero queremos probar la capacidad de nuestro modelo. Una vez que encontramos los valores predichos, podemos usarlos junto con los valores reales (ya sea que las observaciones sean SPAM o no) y crear una matriz de error. La matriz de errores muestra cuántos de los correos electrónicos de SPAM que pensamos que eran SPAM y cuántos no. Lo mismo para correos no SPAM. La línea con la tabla de funciones () muestra que hay 61 correos electrónicos no SPAM que nuestro modelo predijo como SPAM y 458 correos electrónicos SPAM que nuestro modelo predijo como no SPAM. El resto de las observaciones fueron pronosticadas correctamente. La última línea del código calcula el error de predicción.

Una vez que haya realizado el análisis preliminar, debe interpretar los resultados para que otros sepan qué conclusiones se pueden sacar de su análisis. Debe tener cuidado de no confundir las siguientes palabras: Describe (solo si observa un fenómeno sin hacer ningún análisis inferencial o predictivo). Se correlaciona con / asociado con (solo si observa la asociación entre variables sin ninguna interpretación causal). Conduce a / causas (solo si ha realizado un análisis de inferencia causal). Predice (solo si ha realizado análisis predictivo).

Asegúrese de dar suficiente explicación a su análisis. Dé una explicación de lo que sus números dicen (y no dicen). Si haces análisis de regresión, interpreta los coeficientes. Interpretar medidas de incertidumbre.

En nuestro ejemplo, aquí están algunas de las interpretaciones que podemos dar. La fracción de caracteres que son signos de dólar se puede usar para predecir si un correo electrónico es Spam. Cualquier cosa con más de 6,6% de signos de dólar se clasifica como Spam. Más signos de dólar siempre significa más Spam bajo nuestra predicción. Nuestra tasa de error de conjunto de prueba fue de 22.4 por ciento.

Un buen analista es una buena crítica de su trabajo, ya que el analista conoce mejor los datos y los métodos. Su autocrítica y auto desafío deben comenzar desde el principio: la pregunta. ¿Su pregunta es hecha correctamente? Desafíe Desafíe sus datos y asegúrese de que sus datos sean lo suficientemente buenos para su pregunta. Compruebe si la limpieza y el procesamiento de los datos se realizan correctamente. Desafía tus métodos; es el mejor método que podría usar, dada su pregunta y sus datos. Compruebe si sus conclusiones se extraen correctamente. Hay varias formas de medir la incertidumbre de su modelo. Compruebe si ha utilizado la mejor medida. Siempre incluyes variables especificas en tu modelo. Asegúrese de haber incluido los que tengan sentido independientemente de si hacen que sus resultados se vean bien. Y, finalmente, piense en posibles análisis alternativos: reconozca que podría haber enfoques alternativos para su pregunta, como el uso de datos, métodos, etc. Reconociéndolos demostrará cierta honestidad de su parte y allanará el camino para futuros análisis.

Una vez que haya terminado con el análisis y la verificación de la credibilidad de su análisis, comience a escribir sus resultados. Estos son algunos de los pasos importantes: Dirigir con la pregunta. Resumir los análisis en la historia. No incluya todos los análisis, inclúyalo si es necesario para la historia o si es necesario para enfrentar un desafío. Ordenar los análisis según la historia, en lugar de cronológicamente. Incluye "bonitas"  figuras que contribuyen a la historia.

En nuestro ejemplo, deberíamos preguntar: ¿Puede usar las características cuantitativas de los correos electrónicos para clasificarlos como SPAM / HAM? Luego, describa el enfoque, como la fuente de nuestros datos de SPAM y cómo creamos conjuntos de entrenamiento / prueba, relaciones exploradas, elija un modelo logístico en el conjunto de entrenamiento por validación cruzada.

Interpretar los resultados. Por ejemplo, el número de signos de dólar parece razonable, por ejemplo, "Hacer dinero en efectivo desde casa signo de dólar signo de dólar signo de dólar". Desafío de resultados. Por ejemplo, el 78% no es tan bueno, podría usar más variables o Por qué usa la regresión logística.

Como aprendió en las lecciones anteriores, asegúrese de documentar cada paso. Esto es importante por dos razones: para usted en el futuro y para otros para rehacer su análisis. Usar Rmarkdown es una buena manera de acompañar su análisis con buena documentación. Por lo tanto, es importante que los archivos tengan el nombre correcto. Hay una explicación de los datos, cada archivo de código tiene una descripción de lo que hace y donde quiera que agregue comentarios para fragmentos de código importantes dentro de sus archivos de código.
